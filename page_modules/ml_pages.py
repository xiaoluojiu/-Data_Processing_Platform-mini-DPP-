"""
æœºå™¨å­¦ä¹ ç›¸å…³é¡µé¢æ¨¡å—
åŒ…å«æœºå™¨å­¦ä¹ åˆ†æã€ç›‘ç£å­¦ä¹ ã€èšç±»ã€é™ç»´ã€å…³è”è§„åˆ™ç­‰é¡µé¢
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from streamlit_option_menu import option_menu
from sklearn.model_selection import train_test_split
from collections import Counter

# å¯¼å…¥æœºå™¨å­¦ä¹ æ¨¡å—
from ml_models import (
    prepare_data_for_ml, train_regression_model, 
    train_classification_model, perform_kmeans_clustering,
    find_optimal_k, perform_dbscan_clustering,
    perform_pca, perform_apriori, perform_fpgrowth
)
from ml_visualization import (
    plot_confusion_matrix_heatmap, plot_roc_curve,
    plot_learning_curve, plot_decision_tree_structure,
    plot_prediction_distribution, plot_silhouette_plot,
    plot_pca_scatter, plot_rules_heatmap, plot_rules_sankey,
    plot_residual_analysis, plot_prediction_vs_actual,
    plot_feature_interaction_heatmap, plot_error_distribution,
    plot_classification_report_heatmap
)
from visualization import (
    create_residual_plot, create_feature_importance_plot
)


def show_ml_analysis():
    """æœºå™¨å­¦ä¹ é¡µé¢"""
    st.markdown("### ğŸ¤– æœºå™¨å­¦ä¹ ä¸å»ºæ¨¡")
    
    df = st.session_state.df_cleaned if st.session_state.df_cleaned is not None else st.session_state.df
    
    if df is None:
        st.warning("âš ï¸ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
        return
    
    # é¡¶éƒ¨ä»»åŠ¡é€‰æ‹©æ¡
    task_type = option_menu(
        menu_title=None,
        options=["åˆ†ç±»", "å›å½’", "èšç±»", "é™ç»´", "å…³è”è§„åˆ™"],
        icons=["diagram-3", "graph-up-arrow", "boxes", "fullscreen-exit", "link"],
        orientation="horizontal",
        styles={"nav-link": {"font-size": "0.9rem"}}
    )
    
    st.divider()
    
    if task_type in ["åˆ†ç±»", "å›å½’"]:
        _show_ml_supervised(df, task_type)
    elif task_type == "èšç±»":
        _show_ml_clustering(df)
    elif task_type == "é™ç»´":
        _show_ml_pca(df)
    elif task_type == "å…³è”è§„åˆ™":
        _show_ml_rules(df)


def _show_ml_supervised(df, task_type):
    """ç›‘ç£å­¦ä¹ å­é¡µé¢"""
    col_settings, col_results = st.columns([1, 3], gap="large")
    
    with col_settings:
        st.markdown("#### âš™ï¸ æ¨¡å‹é…ç½®")
        target_col = st.selectbox("ç›®æ ‡å˜é‡", df.columns.tolist(), key='ml_target')
        
        if not target_col:
            return

        # è‡ªåŠ¨å»ºè®®
        target_dtype = df[target_col].dtype
        unique_count = df[target_col].nunique()
        is_numeric = pd.api.types.is_numeric_dtype(target_dtype)
        
        suggested = "åˆ†ç±»" if (not is_numeric or unique_count <= 20) else "å›å½’"
        if task_type != suggested:
            st.info(f"ğŸ’¡ æ£€æµ‹åˆ°ç›®æ ‡å˜é‡ç‰¹æ€§ï¼Œå»ºè®®ä½¿ç”¨ã€{suggested}ã€‘ä»»åŠ¡")

        # ç‰¹å¾é€‰æ‹©
        available_features = [c for c in df.columns if c != target_col]
        use_all_features = st.checkbox("ä½¿ç”¨æ‰€æœ‰ç‰¹å¾", value=True)
        if use_all_features:
            selected_features = available_features
        else:
            selected_features = st.multiselect("é€‰æ‹©ç‰¹å¾", available_features, default=available_features[:5])
        
        st.divider()
        
        # æ¨¡å‹é€‰æ‹©
        auto_optimize = st.checkbox("ğŸ¤– è‡ªåŠ¨ä¼˜åŒ–å‚æ•°", value=False, help="è‡ªåŠ¨æœç´¢æœ€ä¼˜å‚æ•°ï¼ˆè€—æ—¶è¾ƒé•¿ï¼‰")
        
        if task_type == "åˆ†ç±»":
            model_type = st.selectbox("é€‰æ‹©æ¨¡å‹", ["é€»è¾‘å›å½’", "æœ´ç´ è´å¶æ–¯", "KNN", "å†³ç­–æ ‘"])
            tree_algorithm = None
            if model_type == "å†³ç­–æ ‘":
                tree_algorithm = st.selectbox("ç®—æ³•", ["CART", "ID3 (ä¿¡æ¯å¢ç›Š)", "C4.5 (å¢ç›Šç‡)"])
        else:
            model_type = st.selectbox("é€‰æ‹©æ¨¡å‹", ["çº¿æ€§å›å½’", "KNNå›å½’", "å†³ç­–æ ‘å›å½’"])
            tree_algorithm = None

        # ç®€å•çš„å‚æ•°é¢æ¿ (æ‰‹åŠ¨æ¨¡å¼ä¸‹)
        params = {}
        if not auto_optimize:
            if "KNN" in model_type:
                params['n_neighbors'] = st.slider("Kå€¼", 1, 20, 5)
            elif "å†³ç­–æ ‘" in model_type:
                params['max_depth'] = st.slider("æœ€å¤§æ·±åº¦", 1, 20, 10)
        
        if tree_algorithm:
            params['tree_algorithm'] = tree_algorithm
        
        st.divider()
        
        # å¯è§†åŒ–é€‰é¡¹ï¼ˆå‰ç½®ï¼Œè®­ç»ƒå‰é€‰æ‹©ï¼‰
        st.markdown("#### ğŸ“ˆ å¯è§†åŒ–é€‰é¡¹ï¼ˆè®­ç»ƒå‰é€‰æ‹©ï¼‰")
        with st.expander("é€‰æ‹©è¦ç”Ÿæˆçš„å¯è§†åŒ–å›¾è¡¨", expanded=False):
            if task_type == "åˆ†ç±»":
                st.markdown("**åŸºç¡€è¯„ä¼°**")
                viz_cm = st.checkbox("æ··æ·†çŸ©é˜µ", value=True, key="viz_cm")
                viz_roc = st.checkbox("ROCæ›²çº¿", value=False, key="viz_roc")
                viz_report = st.checkbox("åˆ†ç±»æŠ¥å‘Šçƒ­åŠ›å›¾", value=False, key="viz_report")
                
                st.markdown("**é«˜çº§åˆ†æ**")
                viz_lc = st.checkbox("å­¦ä¹ æ›²çº¿", value=False, key="viz_lc", help="è€—æ—¶è¾ƒé•¿")
                viz_fi = st.checkbox("ç‰¹å¾é‡è¦æ€§", value=True, key="viz_fi")
                viz_inter = st.checkbox("ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾", value=False, key="viz_inter")
                viz_dist = st.checkbox("é¢„æµ‹åˆ†å¸ƒ", value=False, key="viz_dist")
                viz_tree = st.checkbox("å†³ç­–æ ‘ç»“æ„", value=False, key="viz_tree")
                
                # ä¿å­˜åˆ°session_state
                st.session_state.viz_options[task_type] = {
                    "æ··æ·†çŸ©é˜µ": viz_cm,
                    "ROCæ›²çº¿": viz_roc,
                    "åˆ†ç±»æŠ¥å‘Šçƒ­åŠ›å›¾": viz_report,
                    "å­¦ä¹ æ›²çº¿": viz_lc,
                    "ç‰¹å¾é‡è¦æ€§": viz_fi,
                    "ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾": viz_inter,
                    "é¢„æµ‹åˆ†å¸ƒ": viz_dist,
                    "å†³ç­–æ ‘ç»“æ„": viz_tree
                }
            else:  # å›å½’
                st.markdown("**åŸºç¡€è¯„ä¼°**")
                viz_res = st.checkbox("æ®‹å·®å›¾", value=True, key="viz_res")
                viz_pva = st.checkbox("é¢„æµ‹å€¼vsçœŸå®å€¼", value=True, key="viz_pva")
                viz_err = st.checkbox("è¯¯å·®åˆ†å¸ƒ", value=False, key="viz_err")
                
                st.markdown("**é«˜çº§åˆ†æ**")
                viz_ra = st.checkbox("æ®‹å·®åˆ†æï¼ˆè¯¦ç»†ï¼‰", value=False, key="viz_ra")
                viz_lc = st.checkbox("å­¦ä¹ æ›²çº¿", value=False, key="viz_lc", help="è€—æ—¶è¾ƒé•¿")
                viz_fi = st.checkbox("ç‰¹å¾é‡è¦æ€§", value=True, key="viz_fi")
                viz_inter = st.checkbox("ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾", value=False, key="viz_inter")
                
                # ä¿å­˜åˆ°session_state
                st.session_state.viz_options[task_type] = {
                    "æ®‹å·®å›¾": viz_res,
                    "é¢„æµ‹å€¼vsçœŸå®å€¼": viz_pva,
                    "è¯¯å·®åˆ†å¸ƒ": viz_err,
                    "æ®‹å·®åˆ†æ": viz_ra,
                    "å­¦ä¹ æ›²çº¿": viz_lc,
                    "ç‰¹å¾é‡è¦æ€§": viz_fi,
                    "ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾": viz_inter
                }

        train_btn = st.button("ğŸš€ å¼€å§‹è®­ç»ƒ", type="primary", use_container_width=True)

    with col_results:
        if train_btn and len(selected_features) > 0:
            with st.spinner(f"æ­£åœ¨è®­ç»ƒ {model_type}..."):
                try:
                    task_code = 'classification' if task_type == "åˆ†ç±»" else 'regression'
                    
                    # 1. å‡†å¤‡æ•°æ®
                    X, y, feature_names, _ = prepare_data_for_ml(
                        df, target_col, feature_columns=selected_features, task_type=task_code
                    )
                    
                    # 2. åˆ’åˆ†
                    stratify = y if task_code == 'classification' and y.dtype != 'float' else None
                    try:
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42, stratify=stratify
                        )
                    except:
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42
                        )

                    # 3. è®­ç»ƒ
                    if task_type == "åˆ†ç±»":
                        model_map = {
                            "é€»è¾‘å›å½’": "logistic", "æœ´ç´ è´å¶æ–¯": "naive_bayes", "KNN": "knn",
                            "å†³ç­–æ ‘": "tree"
                        }
                        results = train_classification_model(
                            X_train, y_train, X_test, y_test, 
                            model_type=model_map[model_type], auto_optimize=auto_optimize, **params
                        )
                    else:
                        model_map = {
                            "çº¿æ€§å›å½’": "linear", "KNNå›å½’": "knn", "å†³ç­–æ ‘å›å½’": "tree"
                        }
                        results = train_regression_model(
                            X_train, y_train, X_test, y_test, 
                            model_type=model_map[model_type], auto_optimize=auto_optimize, **params
                        )
                    
                    st.session_state.ml_results = results
                    
                    # ä¿å­˜è®­ç»ƒé…ç½®
                    train_config = {
                        'task_type': task_type,
                        'model_type': model_type,
                        'target_col': target_col,
                        'selected_features': selected_features,
                        'auto_optimize': auto_optimize,
                        'params': params,
                        'feature_names': feature_names,
                        'train_size': len(X_train),
                        'test_size': len(X_test)
                    }
                    st.session_state.ml_train_config = train_config
                    
                    st.toast("è®­ç»ƒå®Œæˆï¼", icon="âœ…")
                    
                    # 4. å±•ç¤ºç»“æœï¼ˆä¼ å…¥å¯è§†åŒ–é€‰é¡¹ï¼‰
                    viz_opts = st.session_state.viz_options.get(task_type, {})
                    _show_supervised_results(results, task_type, feature_names, X_train, y_train, X_test, y_test, 
                                            train_config, viz_opts)
                    
                except Exception as e:
                    st.error(f"è®­ç»ƒå¤±è´¥: {str(e)}")
                    st.exception(e)


def _show_supervised_results(results, task_type, feature_names, X_train, y_train, X_test, y_test, train_config, viz_opts):
    """å±•ç¤ºç›‘ç£å­¦ä¹ ç»“æœ"""
    st.markdown("#### ğŸ“Š è®­ç»ƒç»“æœ")
    
    # æŒ‡æ ‡å¡ç‰‡
    metrics = results['metrics']
    cols = st.columns(len(metrics))
    for idx, (k, v) in enumerate(metrics.items()):
        if isinstance(v, (int, float)):
            cols[idx].metric(k, f"{v:.4f}")
            
    if results.get('best_params'):
        with st.expander("ğŸ” æœ€ä¼˜å‚æ•°é…ç½®", expanded=True):
            st.json(results['best_params'])
    
    # å­˜å‚¨ç”Ÿæˆçš„å›¾è¡¨
    generated_charts = {}
    
    st.markdown("---")
    st.markdown("#### ğŸ“ˆ å¯è§†åŒ–ç»“æœï¼ˆæ ¹æ®è®­ç»ƒå‰é€‰æ‹©çš„é€‰é¡¹ç”Ÿæˆï¼‰")
    
    # æ ¹æ®è®­ç»ƒå‰é€‰æ‹©çš„å¯è§†åŒ–é€‰é¡¹ç”Ÿæˆå›¾è¡¨
    if task_type == "åˆ†ç±»":
        # åŸºç¡€è¯„ä¼°
        if viz_opts.get("æ··æ·†çŸ©é˜µ", False):
            st.markdown("##### æ··æ·†çŸ©é˜µ")
            fig_cm = plot_confusion_matrix_heatmap(y_test, results['y_pred'])
            st.plotly_chart(fig_cm, use_container_width=True)
            generated_charts["æ··æ·†çŸ©é˜µ"] = fig_cm
        
        if viz_opts.get("ROCæ›²çº¿", False) and hasattr(results['model'], 'predict_proba'):
            st.markdown("##### ROCæ›²çº¿")
            fig_roc = plot_roc_curve(y_test, results['model'].predict_proba(X_test))
            st.plotly_chart(fig_roc, use_container_width=True)
            generated_charts["ROCæ›²çº¿"] = fig_roc
        
        if viz_opts.get("åˆ†ç±»æŠ¥å‘Šçƒ­åŠ›å›¾", False):
            st.markdown("##### åˆ†ç±»æŠ¥å‘Šçƒ­åŠ›å›¾")
            fig_report = plot_classification_report_heatmap(y_test, results['y_pred'])
            if fig_report:
                st.plotly_chart(fig_report, use_container_width=True)
                generated_charts["åˆ†ç±»æŠ¥å‘Šçƒ­åŠ›å›¾"] = fig_report
        
        # é«˜çº§åˆ†æ
        if viz_opts.get("å­¦ä¹ æ›²çº¿", False):
            st.markdown("##### å­¦ä¹ æ›²çº¿")
            with st.spinner("ç”Ÿæˆå­¦ä¹ æ›²çº¿ä¸­ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰..."):
                fig_lc = plot_learning_curve(results['model'], X_train, y_train)
                st.plotly_chart(fig_lc, use_container_width=True)
                generated_charts["å­¦ä¹ æ›²çº¿"] = fig_lc
        
        if viz_opts.get("ç‰¹å¾é‡è¦æ€§", False) and results.get('feature_importance'):
            st.markdown("##### ç‰¹å¾é‡è¦æ€§")
            try:
                if isinstance(results['feature_importance'], dict) and len(results['feature_importance']) > 0:
                    fig = create_feature_importance_plot(results['feature_importance'])
                    st.plotly_chart(fig, use_container_width=True)
                    generated_charts["ç‰¹å¾é‡è¦æ€§"] = fig
                else:
                    st.warning("ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            except Exception as e:
                st.error(f"ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾å¤±è´¥: {str(e)}")
        
        if viz_opts.get("ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾", False):
            st.markdown("##### ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾")
            with st.spinner("ç”Ÿæˆç‰¹å¾äº¤äº’çƒ­åŠ›å›¾ä¸­..."):
                try:
                    fig_inter = plot_feature_interaction_heatmap(X_train, feature_names)
                    if fig_inter:
                        st.plotly_chart(fig_inter, use_container_width=True)
                        generated_charts["ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾"] = fig_inter
                except Exception as e:
                    st.error(f"ç”Ÿæˆç‰¹å¾äº¤äº’çƒ­åŠ›å›¾å¤±è´¥: {str(e)}")
        
        if viz_opts.get("é¢„æµ‹åˆ†å¸ƒ", False):
            st.markdown("##### é¢„æµ‹åˆ†å¸ƒ")
            try:
                fig_dist = plot_prediction_distribution(y_test, results['y_pred'], task_type='classification')
                if fig_dist:
                    st.plotly_chart(fig_dist, use_container_width=True)
                    generated_charts["é¢„æµ‹åˆ†å¸ƒ"] = fig_dist
            except Exception as e:
                st.error(f"ç”Ÿæˆé¢„æµ‹åˆ†å¸ƒå›¾å¤±è´¥: {str(e)}")
        
        if viz_opts.get("å†³ç­–æ ‘ç»“æ„", False):
            st.markdown("##### å†³ç­–æ ‘ç»“æ„")
            try:
                model_str = str(type(results['model']).__name__).lower()
                if 'tree' in model_str or 'decision' in model_str:
                    img = plot_decision_tree_structure(results['model'], feature_names, max_depth=5)
                    if img:
                        st.image(f"data:image/png;base64,{img}")
                        generated_charts["å†³ç­–æ ‘ç»“æ„"] = img
                    else:
                        st.warning("æ— æ³•ç”Ÿæˆå†³ç­–æ ‘ç»“æ„å›¾")
                else:
                    st.info("å½“å‰æ¨¡å‹ä¸æ˜¯å†³ç­–æ ‘ï¼Œæ— æ³•æ˜¾ç¤ºæ ‘ç»“æ„")
            except Exception as e:
                st.error(f"ç”Ÿæˆå†³ç­–æ ‘ç»“æ„å¤±è´¥: {str(e)}")
    
    else:  # å›å½’ä»»åŠ¡
        # åŸºç¡€è¯„ä¼°
        if viz_opts.get("æ®‹å·®å›¾", False):
            st.markdown("##### æ®‹å·®å›¾")
            fig_res = create_residual_plot(y_test, results['y_pred'])
            st.plotly_chart(fig_res, use_container_width=True)
            generated_charts["æ®‹å·®å›¾"] = fig_res
        
        if viz_opts.get("é¢„æµ‹å€¼vsçœŸå®å€¼", False):
            st.markdown("##### é¢„æµ‹å€¼ vs çœŸå®å€¼")
            fig_pva = plot_prediction_vs_actual(y_test, results['y_pred'], task_type='regression')
            st.plotly_chart(fig_pva, use_container_width=True)
            generated_charts["é¢„æµ‹å€¼vsçœŸå®å€¼"] = fig_pva
        
        if viz_opts.get("è¯¯å·®åˆ†å¸ƒ", False):
            st.markdown("##### è¯¯å·®åˆ†å¸ƒ")
            fig_err = plot_error_distribution(y_test, results['y_pred'])
            st.plotly_chart(fig_err, use_container_width=True)
            generated_charts["è¯¯å·®åˆ†å¸ƒ"] = fig_err
        
        # é«˜çº§åˆ†æ
        if viz_opts.get("æ®‹å·®åˆ†æ", False):
            st.markdown("##### æ®‹å·®åˆ†æï¼ˆè¯¦ç»†ï¼‰")
            with st.spinner("ç”Ÿæˆæ®‹å·®åˆ†æä¸­..."):
                fig_ra = plot_residual_analysis(y_test, results['y_pred'])
                st.plotly_chart(fig_ra, use_container_width=True)
                generated_charts["æ®‹å·®åˆ†æ"] = fig_ra
        
        if viz_opts.get("å­¦ä¹ æ›²çº¿", False):
            st.markdown("##### å­¦ä¹ æ›²çº¿")
            with st.spinner("ç”Ÿæˆå­¦ä¹ æ›²çº¿ä¸­ï¼ˆå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰..."):
                fig_lc = plot_learning_curve(results['model'], X_train, y_train)
                st.plotly_chart(fig_lc, use_container_width=True)
                generated_charts["å­¦ä¹ æ›²çº¿"] = fig_lc
        
        if viz_opts.get("ç‰¹å¾é‡è¦æ€§", False) and results.get('feature_importance'):
            st.markdown("##### ç‰¹å¾é‡è¦æ€§")
            try:
                if isinstance(results['feature_importance'], dict) and len(results['feature_importance']) > 0:
                    fig = create_feature_importance_plot(results['feature_importance'])
                    st.plotly_chart(fig, use_container_width=True)
                    generated_charts["ç‰¹å¾é‡è¦æ€§"] = fig
                else:
                    st.warning("ç‰¹å¾é‡è¦æ€§æ•°æ®ä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®")
            except Exception as e:
                st.error(f"ç”Ÿæˆç‰¹å¾é‡è¦æ€§å›¾å¤±è´¥: {str(e)}")
        
        if viz_opts.get("ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾", False):
            st.markdown("##### ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾")
            with st.spinner("ç”Ÿæˆç‰¹å¾äº¤äº’çƒ­åŠ›å›¾ä¸­..."):
                try:
                    fig_inter = plot_feature_interaction_heatmap(X_train, feature_names)
                    if fig_inter:
                        st.plotly_chart(fig_inter, use_container_width=True)
                        generated_charts["ç‰¹å¾äº¤äº’çƒ­åŠ›å›¾"] = fig_inter
                except Exception as e:
                    st.error(f"ç”Ÿæˆç‰¹å¾äº¤äº’çƒ­åŠ›å›¾å¤±è´¥: {str(e)}")


def _show_ml_clustering(df):
    """èšç±»åˆ†æå­é¡µé¢"""
    col_settings, col_results = st.columns([1, 3], gap="large")
    
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    if len(numeric_cols) < 2:
        st.error("èšç±»éœ€è¦è‡³å°‘ 2 ä¸ªæ•°å€¼å‹ç‰¹å¾")
        return

    with col_settings:
        st.markdown("#### âš™ï¸ èšç±»é…ç½®")
        algo = st.selectbox("ç®—æ³•", ["K-means", "DBSCAN"])
        cols = st.multiselect("ç‰¹å¾é€‰æ‹©", numeric_cols, default=numeric_cols[:min(3, len(numeric_cols))])
        
        # æ•°æ®æ ‡å‡†åŒ–é€‰é¡¹
        normalize = st.checkbox("æ ‡å‡†åŒ–æ•°æ®", value=True, help="å»ºè®®å¼€å¯ï¼Œå¯æå‡èšç±»æ•ˆæœ")
        
        # å¤§æ•°æ®é›†é‡‡æ ·é€‰é¡¹
        max_samples = st.number_input("æœ€å¤§æ ·æœ¬æ•°ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰", min_value=100, max_value=10000, value=5000, step=500,
                                      help="è¶…è¿‡æ­¤æ•°é‡çš„æ•°æ®å°†è¿›è¡Œé‡‡æ ·ï¼Œä»¥æå‡æ€§èƒ½")
        
        params = {}
        if algo == "K-means":
            if cols:
                X_temp = df[cols].dropna()
                max_k = min(10, len(X_temp) // 2) if len(X_temp) > 0 else 10
                params['n_clusters'] = st.slider("èšç±»æ•° (K)", 2, max(2, max_k), min(3, max_k))
            else:
                params['n_clusters'] = 3
            
            # å¯»æ‰¾æœ€ä¼˜KåŠŸèƒ½
            if st.button("ğŸ” å¯»æ‰¾æœ€ä¼˜ K", use_container_width=True):
                st.session_state.find_optimal_k = True
        else:
            params['eps'] = st.slider("Eps (åŠå¾„)", 0.1, 5.0, 0.5, 0.1)
            params['min_samples'] = st.slider("Min Samples", 2, 20, 5)
            
        run_cluster = st.button("ğŸš€ æ‰§è¡Œèšç±»", type="primary", use_container_width=True)

    with col_results:
        # å¯»æ‰¾æœ€ä¼˜K
        if st.session_state.get('find_optimal_k', False) and cols:
            st.session_state.find_optimal_k = False
            with st.spinner("æ­£åœ¨å¯»æ‰¾æœ€ä¼˜Kå€¼ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰..."):
                try:
                    X = df[cols].dropna()
                    if len(X) > max_samples:
                        X = X.sample(n=max_samples, random_state=42)
                        st.info(f"âš ï¸ æ•°æ®é‡è¾ƒå¤§ï¼Œå·²é‡‡æ · {max_samples} ä¸ªæ ·æœ¬è¿›è¡Œåˆ†æ")
                    
                    if normalize:
                        from sklearn.preprocessing import StandardScaler
                        scaler = StandardScaler()
                        X_scaled = scaler.fit_transform(X)
                        X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
                    
                    optimal_result = find_optimal_k(X, max_k=min(10, len(X) // 2))
                    
                    # ç»˜åˆ¶è‚˜éƒ¨æ³•åˆ™å’Œè½®å»“ç³»æ•°å›¾
                    col_a, col_b = st.columns(2)
                    with col_a:
                        fig_elbow = go.Figure()
                        fig_elbow.add_trace(go.Scatter(
                            x=optimal_result['k_range'],
                            y=optimal_result['inertias'],
                            mode='lines+markers',
                            name='æƒ¯æ€§',
                            line=dict(color='blue', width=2)
                        ))
                        fig_elbow.update_layout(
                            title='è‚˜éƒ¨æ³•åˆ™ (Elbow Method)',
                            xaxis_title='Kå€¼',
                            yaxis_title='æƒ¯æ€§ (Inertia)',
                            template='plotly_white',
                            height=400
                        )
                        st.plotly_chart(fig_elbow, use_container_width=True)
                    
                    with col_b:
                        fig_sil = go.Figure()
                        fig_sil.add_trace(go.Scatter(
                            x=optimal_result['k_range'],
                            y=optimal_result['silhouette_scores'],
                            mode='lines+markers',
                            name='è½®å»“ç³»æ•°',
                            line=dict(color='green', width=2)
                        ))
                        fig_sil.add_vline(
                            x=optimal_result['optimal_k'],
                            line_dash="dash",
                            line_color="red",
                            annotation_text=f"æœ€ä¼˜K={optimal_result['optimal_k']}"
                        )
                        fig_sil.update_layout(
                            title='è½®å»“ç³»æ•°åˆ†æ',
                            xaxis_title='Kå€¼',
                            yaxis_title='è½®å»“ç³»æ•°',
                            template='plotly_white',
                            height=400
                        )
                        st.plotly_chart(fig_sil, use_container_width=True)
                    
                    st.success(f"âœ… æ¨èçš„æœ€ä¼˜Kå€¼: **{optimal_result['optimal_k']}** (è½®å»“ç³»æ•°: {max(optimal_result['silhouette_scores']):.4f})")
                    
                except Exception as e:
                    st.error(f"å¯»æ‰¾æœ€ä¼˜Kå¤±è´¥: {str(e)}")
                    st.exception(e)
        
        # æ‰§è¡Œèšç±»
        if run_cluster and cols:
            if len(cols) < 2:
                st.error("âš ï¸ èšç±»éœ€è¦è‡³å°‘é€‰æ‹© 2 ä¸ªç‰¹å¾")
            else:
                with st.spinner("æ­£åœ¨èšç±»..."):
                    try:
                        X = df[cols].dropna()
                        original_size = len(X)
                        
                        # æ•°æ®é‡‡æ ·ï¼ˆå¦‚æœæ•°æ®é‡å¤ªå¤§ï¼‰
                        if len(X) > max_samples:
                            X = X.sample(n=max_samples, random_state=42)
                            st.warning(f"âš ï¸ æ•°æ®é‡è¾ƒå¤§ ({original_size} è¡Œ)ï¼Œå·²é‡‡æ · {max_samples} è¡Œè¿›è¡Œåˆ†æä»¥æå‡æ€§èƒ½")
                        
                        if len(X) < 2:
                            st.error("âš ï¸ æœ‰æ•ˆæ•°æ®æ ·æœ¬ä¸è¶³ï¼ˆåˆ é™¤ç¼ºå¤±å€¼åå°‘äº2ä¸ªï¼‰")
                        else:
                            # æ•°æ®æ ‡å‡†åŒ–
                            if normalize:
                                from sklearn.preprocessing import StandardScaler
                                scaler = StandardScaler()
                                X_scaled = scaler.fit_transform(X)
                                X = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)
                            
                            if algo == "K-means":
                                if params['n_clusters'] > len(X):
                                    st.error(f"âš ï¸ èšç±»æ•° ({params['n_clusters']}) ä¸èƒ½å¤§äºæ ·æœ¬æ•° ({len(X)})")
                                else:
                                    res = perform_kmeans_clustering(X, params['n_clusters'])
                            else:
                                res = perform_dbscan_clustering(X, params['eps'], params['min_samples'])
                            
                            st.session_state.ml_results = res
                            
                            # æ˜¾ç¤ºç»“æœ
                            if res.get('silhouette_score') is not None:
                                st.success(f"âœ… èšç±»å®Œæˆï¼è½®å»“ç³»æ•°: {res['silhouette_score']:.4f}")
                            else:
                                st.success("âœ… èšç±»å®Œæˆï¼")
                            
                            if algo == "DBSCAN":
                                st.info(f"ğŸ“Š å‘ç° {res.get('n_clusters', 0)} ä¸ªèšç±»ï¼Œ{res.get('n_noise', 0)} ä¸ªå™ªå£°ç‚¹")
                            
                            # ä¿å­˜èšç±»é…ç½®å’Œç»“æœ
                            cluster_config = {
                                'task_type': 'èšç±»',
                                'algorithm': algo,
                                'selected_features': cols,
                                'normalize': normalize,
                                'params': params,
                                'n_samples': len(X)
                            }
                            st.session_state.ml_train_config = cluster_config
                            
                            # å¯è§†åŒ–
                            tab1, tab2, tab3, tab4 = st.tabs(["æ•£ç‚¹åˆ†å¸ƒ", "è½®å»“ç³»æ•°åˆ†æ", "èšç±»åˆ†æ", "ç‰¹å¾åˆ†å¸ƒ"])
                            with tab1:
                                if len(cols) >= 2:
                                    # é™åˆ¶æ•£ç‚¹å›¾ç‚¹æ•°ï¼Œé¿å…æµè§ˆå™¨å¡é¡¿
                                    plot_data = df.loc[X.index].copy()
                                    plot_data['cluster'] = res['labels'].astype(str)
                                    
                                    # å¦‚æœæ•°æ®ç‚¹å¤ªå¤šï¼Œè¿›è¡Œé‡‡æ ·
                                    max_plot_points = 2000
                                    if len(plot_data) > max_plot_points:
                                        plot_data = plot_data.sample(n=max_plot_points, random_state=42)
                                        st.caption(f"âš ï¸ æ•£ç‚¹å›¾å·²é‡‡æ ·æ˜¾ç¤º {max_plot_points} ä¸ªç‚¹ï¼ˆå…± {len(X)} ä¸ªï¼‰")
                                    
                                    fig = px.scatter(
                                        plot_data, 
                                        x=cols[0], 
                                        y=cols[1], 
                                        color='cluster',
                                        title="èšç±»ç»“æœ (å‰ä¸¤ä¸ªç‰¹å¾)",
                                        labels={'cluster': 'èšç±»æ ‡ç­¾'}
                                    )
                                    fig.update_traces(marker=dict(size=5, opacity=0.6))
                                    
                                    # å¦‚æœæ˜¯K-meansï¼Œæ˜¾ç¤ºèšç±»ä¸­å¿ƒ
                                    if algo == "K-means" and res.get('centers') is not None:
                                        centers = res['centers']
                                        if len(centers) > 0 and len(centers[0]) >= 2:
                                            centers_2d = centers[:, :2] if centers.shape[1] >= 2 else centers
                                            fig.add_trace(go.Scatter(
                                                x=centers_2d[:, 0],
                                                y=centers_2d[:, 1],
                                                mode='markers',
                                                marker=dict(symbol='x', size=15, color='red', line=dict(width=2, color='darkred')),
                                                name='èšç±»ä¸­å¿ƒ',
                                                showlegend=True
                                            ))
                                    
                                    st.plotly_chart(fig, use_container_width=True)
                                else:
                                    st.warning("éœ€è¦è‡³å°‘2ä¸ªç‰¹å¾æ‰èƒ½æ˜¾ç¤ºæ•£ç‚¹å›¾")
                            
                            with tab2:
                                if res.get('silhouette_score') is not None:
                                    fig_sil = plot_silhouette_plot(X.values, res['labels'], max_samples=1000)
                                    if fig_sil:
                                        st.plotly_chart(fig_sil, use_container_width=True)
                                    else:
                                        st.warning("æ— æ³•ç”Ÿæˆè½®å»“ç³»æ•°å›¾")
                                else:
                                    st.info("DBSCAN èšç±»ç»“æœä¸­æ— æ³•è®¡ç®—è½®å»“ç³»æ•°ï¼ˆå¯èƒ½èšç±»æ•°è¿‡å°‘æˆ–å™ªå£°ç‚¹è¿‡å¤šï¼‰")
                            
                            with tab3:
                                # èšç±»å¤§å°åˆ†å¸ƒ
                                cluster_counts = Counter(res['labels'])
                                cluster_sizes = [cluster_counts.get(i, 0) for i in sorted(set(res['labels'])) if i != -1]
                                cluster_labels = [f"èšç±» {i}" for i in sorted(set(res['labels'])) if i != -1]
                                
                                if -1 in cluster_counts:
                                    cluster_labels.append("å™ªå£°ç‚¹")
                                    cluster_sizes.append(cluster_counts[-1])
                                
                                fig_size = px.bar(
                                    x=cluster_labels,
                                    y=cluster_sizes,
                                    title="èšç±»å¤§å°åˆ†å¸ƒ",
                                    labels={'x': 'èšç±»', 'y': 'æ ·æœ¬æ•°'},
                                    color=cluster_sizes,
                                    color_continuous_scale='Viridis'
                                )
                                st.plotly_chart(fig_size, use_container_width=True)
                                
                                # èšç±»ä¸­å¿ƒè·ç¦»çƒ­åŠ›å›¾ï¼ˆä»…K-meansï¼‰
                                if algo == "K-means" and res.get('centers') is not None:
                                    try:
                                        from sklearn.metrics.pairwise import euclidean_distances
                                        centers = res['centers']
                                        distances = euclidean_distances(centers)
                                        
                                        fig_dist = px.imshow(
                                            distances,
                                            labels=dict(x="èšç±»", y="èšç±»", color="è·ç¦»"),
                                            x=[f"èšç±» {i}" for i in range(len(centers))],
                                            y=[f"èšç±» {i}" for i in range(len(centers))],
                                            color_continuous_scale='RdYlBu_r',
                                            title="èšç±»ä¸­å¿ƒè·ç¦»çƒ­åŠ›å›¾",
                                            aspect="auto"
                                        )
                                        st.plotly_chart(fig_dist, use_container_width=True)
                                    except Exception as e:
                                        st.warning(f"æ— æ³•ç”Ÿæˆèšç±»ä¸­å¿ƒè·ç¦»å›¾: {str(e)}")
                            
                            with tab4:
                                # å„ç‰¹å¾åœ¨èšç±»ä¸­çš„åˆ†å¸ƒï¼ˆç®±çº¿å›¾ï¼‰
                                if len(cols) > 0:
                                    selected_feature = st.selectbox("é€‰æ‹©ç‰¹å¾æŸ¥çœ‹åˆ†å¸ƒ", cols, key="cluster_feature_dist")
                                    if selected_feature:
                                        plot_data_dist = df.loc[X.index].copy()
                                        plot_data_dist['cluster'] = res['labels'].astype(str)
                                        
                                        fig_box = px.box(
                                            plot_data_dist,
                                            x='cluster',
                                            y=selected_feature,
                                            title=f"{selected_feature} åœ¨å„èšç±»ä¸­çš„åˆ†å¸ƒ",
                                            color='cluster'
                                        )
                                        st.plotly_chart(fig_box, use_container_width=True)
                            
                            
                    except Exception as e:
                        st.error(f"èšç±»å¤±è´¥: {str(e)}")
                        st.exception(e)


def _show_ml_pca(df):
    """é™ç»´åˆ†æå­é¡µé¢"""
    col_settings, col_results = st.columns([1, 3], gap="large")
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    with col_settings:
        st.markdown("#### âš™ï¸ PCA é…ç½®")
        cols = st.multiselect("ç‰¹å¾é€‰æ‹©", numeric_cols, default=numeric_cols)
        if cols:
            max_comps = min(len(cols), len(df))
            n_comps = st.slider("ä¸»æˆåˆ†æ•°é‡", 2, max(2, max_comps), min(2, max_comps))
        else:
            n_comps = 2
            st.info("è¯·å…ˆé€‰æ‹©ç‰¹å¾")
        run_pca = st.button("ğŸš€ æ‰§è¡Œé™ç»´", type="primary", use_container_width=True)

    with col_results:
        if run_pca and cols:
            if len(cols) < 2:
                st.error("âš ï¸ PCA éœ€è¦è‡³å°‘é€‰æ‹© 2 ä¸ªç‰¹å¾")
            else:
                try:
                    X = df[cols].dropna()
                    if len(X) < 2:
                        st.error("âš ï¸ æœ‰æ•ˆæ•°æ®æ ·æœ¬ä¸è¶³ï¼ˆåˆ é™¤ç¼ºå¤±å€¼åå°‘äº2ä¸ªï¼‰")
                    else:
                        # ç¡®ä¿ä¸»æˆåˆ†æ•°é‡ä¸è¶…è¿‡ç‰¹å¾æ•°é‡
                        max_comps = min(n_comps, len(cols), len(X))
                        if max_comps < n_comps:
                            st.warning(f"âš ï¸ ä¸»æˆåˆ†æ•°é‡å·²è°ƒæ•´ä¸º {max_comps}ï¼ˆå—ç‰¹å¾æ•°å’Œæ ·æœ¬æ•°é™åˆ¶ï¼‰")
                        
                        res = perform_pca(X, max_comps)
                        
                        st.info(f"å‰ {max_comps} ä¸ªä¸»æˆåˆ†è§£é‡Šäº† {res['cumulative_variance'][-1]*100:.2f}% çš„æ–¹å·®")
                        
                        # ä¿å­˜PCAé…ç½®
                        pca_config = {
                            'task_type': 'é™ç»´',
                            'algorithm': 'PCA',
                            'selected_features': cols,
                            'n_components': max_comps,
                            'n_samples': len(X)
                        }
                        st.session_state.ml_train_config = pca_config
                        
                        tab1, tab2 = st.tabs(["æ–¹å·®è§£é‡Šç‡", "2D æŠ•å½±"])
                        generated_charts = {}
                        with tab1:
                            fig = px.bar(
                                y=res['explained_variance'], 
                                x=[f"PC{i+1}" for i in range(len(res['explained_variance']))],
                                title="ä¸»æˆåˆ†æ–¹å·®è§£é‡Šç‡"
                            )
                            st.plotly_chart(fig, use_container_width=True)
                            generated_charts["æ–¹å·®è§£é‡Šç‡"] = fig
                        with tab2:
                            if res['X_transformed'].shape[1] >= 2:
                                fig_pca = plot_pca_scatter(res['X_transformed'])
                                if fig_pca:
                                    st.plotly_chart(fig_pca, use_container_width=True)
                                    generated_charts["2DæŠ•å½±"] = fig_pca
                            else:
                                st.warning("éœ€è¦è‡³å°‘2ä¸ªä¸»æˆåˆ†æ‰èƒ½æ˜¾ç¤º2DæŠ•å½±")
                        
                            
                except Exception as e:
                    st.error(f"PCA é™ç»´å¤±è´¥: {str(e)}")
                    st.exception(e)


def _show_ml_rules(df):
    """å…³è”è§„åˆ™å­é¡µé¢"""
    col_settings, col_results = st.columns([1, 3], gap="large")
    
    with col_settings:
        st.markdown("#### âš™ï¸ å…³è”è§„åˆ™é…ç½®")
        
        algorithm = st.selectbox("ç®—æ³•é€‰æ‹©", ["Apriori", "FP-Growth"], 
                                help="Apriori: ç»å…¸ç®—æ³•ï¼Œé€å±‚ç”Ÿæˆå€™é€‰é›†\nFP-Growth: é«˜æ•ˆç®—æ³•ï¼Œä½¿ç”¨FP-treeç»“æ„")
        
        st.markdown(f"**å½“å‰ç®—æ³•**: {algorithm}")
        if algorithm == "FP-Growth":
            st.info("ğŸ’¡ FP-Growth ç®—æ³•æ¯” Apriori æ›´é«˜æ•ˆï¼Œé€‚åˆå¤§æ•°æ®é›†")
        
        min_sup = st.slider("æœ€å°æ”¯æŒåº¦", 0.01, 0.5, 0.05, 0.01)
        min_conf = st.slider("æœ€å°ç½®ä¿¡åº¦", 0.1, 1.0, 0.5, 0.1)
        run_rules = st.button("ğŸš€ æŒ–æ˜è§„åˆ™", type="primary", use_container_width=True)

    with col_results:
        if run_rules:
            with st.spinner(f"ä½¿ç”¨ {algorithm} ç®—æ³•æŒ–æ˜ä¸­..."):
                try:
                    if algorithm == "Apriori":
                        res = perform_apriori(df, min_sup, min_conf)
                    else:
                        res = perform_fpgrowth(df, min_sup, min_conf)
                    
                    rules = res['rules']
                    
                    rules_config = {
                        'task_type': 'å…³è”è§„åˆ™',
                        'algorithm': res.get('algorithm', algorithm),
                        'min_support': min_sup,
                        'min_confidence': min_conf,
                        'n_rules': len(rules) if not rules.empty else 0
                    }
                    st.session_state.ml_train_config = rules_config
                    
                    if not rules.empty:
                        st.success(f"âœ… ä½¿ç”¨ {algorithm} ç®—æ³•æ‰¾åˆ° {len(rules)} æ¡è§„åˆ™")
                        
                        tab1, tab2, tab3 = st.tabs(["è§„åˆ™åˆ—è¡¨", "çƒ­åŠ›å›¾", "æ¡‘åŸºå›¾"])
                        generated_charts = {}
                        with tab1:
                            st.dataframe(rules, use_container_width=True)
                        with tab2:
                            try:
                                fig_heat = plot_rules_heatmap(rules)
                                if fig_heat: 
                                    st.plotly_chart(fig_heat, use_container_width=True)
                                    generated_charts["è§„åˆ™çƒ­åŠ›å›¾"] = fig_heat
                                else:
                                    st.info("æ— æ³•ç”Ÿæˆçƒ­åŠ›å›¾")
                            except Exception as e:
                                st.warning(f"ç”Ÿæˆçƒ­åŠ›å›¾æ—¶å‡ºé”™: {str(e)}")
                        with tab3:
                            try:
                                fig_sankey = plot_rules_sankey(rules)
                                if fig_sankey: 
                                    st.plotly_chart(fig_sankey, use_container_width=True)
                                    generated_charts["è§„åˆ™æ¡‘åŸºå›¾"] = fig_sankey
                                else:
                                    st.info("æ— æ³•ç”Ÿæˆæ¡‘åŸºå›¾")
                            except Exception as e:
                                st.warning(f"ç”Ÿæˆæ¡‘åŸºå›¾æ—¶å‡ºé”™: {str(e)}")
                        
                    else:
                        st.warning("æœªæ‰¾åˆ°æ»¡è¶³æ¡ä»¶çš„è§„åˆ™ï¼Œè¯·å°è¯•é™ä½æœ€å°æ”¯æŒåº¦æˆ–æœ€å°ç½®ä¿¡åº¦")
                except Exception as e:
                    st.error(f"å…³è”è§„åˆ™æŒ–æ˜å¤±è´¥: {str(e)}")
                    st.exception(e)

